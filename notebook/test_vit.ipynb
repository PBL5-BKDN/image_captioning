{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T19:18:21.945911Z",
     "start_time": "2025-06-06T19:18:02.782662Z"
    }
   },
   "source": [
    "\n",
    "from model.VIT import VIT\n",
    "import os.path\n",
    "\n",
    "from processing.image_processing import process_image\n",
    "from settings import BASE_DIR\n",
    "from train.helper import load_checkpoint\n",
    "\n",
    "model_path = os.path.join(BASE_DIR, \"train\", \"model\",\"vit\", \"best_model.pth\")\n",
    "model, _, _ = load_checkpoint(VIT, model_path, 0.0001)\n",
    "model\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VIT(\n",
       "  (encoder_vit): EncoderVIT(\n",
       "    (patch_embedding): PatchEmbedding(\n",
       "      (conv): Conv2d(3, 200, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (encoder_blocks): ModuleList(\n",
       "      (0-2): 3 x EncoderBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=200, out_features=512, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "    (embed_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder_vit): DecoderVIT(\n",
       "    (embedding): Embedding(\n",
       "      (token_embedding): Embedding(7472, 200, padding_idx=0)\n",
       "    )\n",
       "    (pos_embedding): PositionalEncoding()\n",
       "    (decoder_blocks): ModuleList(\n",
       "      (0-2): 3 x DecoderBlock(\n",
       "        (mask_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (layer_norm_1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (e_d_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (layer_norm_2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=200, out_features=512, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (4): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (layer_norm_3): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=200, out_features=7472, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T19:18:22.107667Z",
     "start_time": "2025-06-06T19:18:22.102038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from settings import DEVICE\n",
    "import torch\n",
    "\n",
    "vocab = model.vocab\n",
    "print(vocab.vocab_size)\n",
    "def generate_caption(model, image, vocab, max_len=40):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(DEVICE).unsqueeze(0)  # (1, 3, 224, 224)\n",
    "\n",
    "        # Encode ảnh\n",
    "        encoder_output = model.encoder_vit(image)\n",
    "\n",
    "        # Khởi tạo caption đầu vào với <START>\n",
    "        input_ids = [vocab.w2i[\"<START>\"]]\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            input_tensor = torch.tensor([input_ids], device=DEVICE)\n",
    "\n",
    "\n",
    "            # Dự đoán từ tiếp theo\n",
    "            output = model.decoder_vit(input_tensor, encoder_output)\n",
    "            next_token_logits = output[0, -1, :]\n",
    "            next_token = torch.argmax(next_token_logits).item()\n",
    "\n",
    "            if next_token == vocab.w2i[\"<END>\"]:\n",
    "                break\n",
    "\n",
    "            input_ids.append(next_token)\n",
    "\n",
    "        # Chuyển token ID -> từ\n",
    "        caption = [vocab.i2w[idx] for idx in input_ids[1:]]\n",
    "        return \" \".join(caption)"
   ],
   "id": "a718def38ea0c82a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7472\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T19:18:47.627687Z",
     "start_time": "2025-06-06T19:18:47.167573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PIL import Image\n",
    "from processing.image_processing import process_image\n",
    "image = Image.open(\"E:\\\\python_prj\\\\dataset\\\\flickr30k\\\\flickr30k-images\\\\1007129816.jpg\").convert(\"RGB\")\n",
    "image.show()\n",
    "import time\n",
    "start_time = time.time()\n",
    "processed_image = process_image(image)\n",
    "caption = generate_caption(model, processed_image, vocab)\n",
    "print(caption)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to generate caption: {end_time - start_time} seconds\")"
   ],
   "id": "dbc3d3cd5eda34a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man in a white shirt and a woman in a white shirt are sitting on a bench\n",
      "Time taken to generate caption: 0.3828577995300293 seconds\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T19:25:19.687397Z",
     "start_time": "2025-06-06T19:19:03.581924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = []\n",
    "references = []\n",
    "import pandas as pd\n",
    "test_df = pd.read_csv(os.path.join(BASE_DIR, \"dataset\" , \"flickr30k\", \"test.csv\"))\n",
    "import time\n",
    "start_time = time.time()\n",
    "for index, row in test_df.iterrows():\n",
    "    image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "    processed_image = process_image(image)\n",
    "    caption = generate_caption(model, processed_image, vocab)\n",
    "    predictions.append(caption)\n",
    "    references.append(row[\"caption\"])\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to generate caption: {(end_time - start_time)/len(predictions)} seconds\")\n",
    "\n"
   ],
   "id": "2a9e24788eda3980",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to generate caption: 0.07521826376914978 seconds\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T19:34:21.344303Z",
     "start_time": "2025-06-06T19:34:16.196702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "# === Tính toán ===\n",
    "bleu_result = bleu.compute(predictions=predictions, references=references)\n",
    "\n",
    "\n",
    "# === In kết quả ===\n",
    "print(\"BLEU:\", bleu_result)\n",
    "\n"
   ],
   "id": "426333bd651fe45d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: {'bleu': 0.04600579448506702, 'precisions': [0.26633544354515587, 0.07216656503179719, 0.02370455196106499, 0.009832260787002849], 'brevity_penalty': 1.0, 'length_ratio': 1.0115756878131028, 'translation_length': 62395, 'reference_length': 61681}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T08:56:58.467334Z",
     "start_time": "2025-06-04T08:56:52.654518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "meteor = evaluate.load(\"meteor\")\n",
    "meteor_result = meteor.compute(predictions=predictions, references=references)\n",
    "print(\"METEOR:\", meteor_result)"
   ],
   "id": "9500550f32bb4a51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\huynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\huynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\huynh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR: {'meteor': 0.17983583378542836}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T08:57:04.775823Z",
     "start_time": "2025-06-04T08:57:01.884991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "rouge_result = rouge.compute(predictions=predictions, references=references)\n",
    "print(\"ROUGE:\", rouge_result)"
   ],
   "id": "d0ecec072eb9148e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE: {'rouge1': 0.2626811295303458, 'rouge2': 0.06979085488473463, 'rougeL': 0.24099241785757514, 'rougeLsum': 0.24119005268627136}\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
